# 1장. 사용자 수에 따른 규모 확장성

## TL;DR

1.

<hr>
<br>

> - 1명부터 수백만 사용자를 지원하는 시스템을 설계한다.
>
> - 규모 확장성과 관계된 설계 문제를 푸는 데 쓰일 유용한 지식을 습득한다.

<hr>
<br>

## 단일 서버

- 서버 1대에서 웹, 앱, 데이터베이스, 캐시 등을 전부 실행한다.
  > 이미지

### 사용자 요청 처리 흐름

1. 사용자는 도메인 이름(www.google.com)을 이용하여 웹사이트에 접속한다.

   - 이 접속을 위해 도메인 이름을 도메인 이름 서비스(DNS: Domain Name Service)에 물어봐서(질의하여) IP 주소로 변환하는 과정이 필요하다.

   - DNS는 보통 제3 사업자(third party)가 제공하는 유료 서비스(외부 서비스)를 이용하게 되므로 우리 시스템의 일부는 아니다.

2. DNS 조회 결과로 IP 주소가 반환된다.

   - 구글의 경우, IP 주소는 66.249.73.236로 웹 주소이다.

3. 해당 IP 주소로 HTTP(HyperText Transfer Protocol) 요청이 전달된다.

4. 요청을 받은 웹 서버는 HTML 페이지나 JSON 형태의 응답을 반환한다.

### 실제 요청은 두 가지 종류의 단말로부터 온다.

1. 웹 애플리케이션

   - 비즈니스 로직, 데이터 저장 등을 처리하기 위해서 서버 구현용 언어(Java, Python 등)를 사용한다.

   - 프레젠테이션용으로는 클라이언트 구현용 언어(HTML, JavaScript 등)을 사용한다.

2. 모바일 앱

   - 모바일 앱 - 웹 서버 간 통신을 위해 HTTP 프로토콜을 이용한다.

   - HTTP 프로토콜을 통해서 반환될 응답 데이터의 포맷으로는 보통 간결함이 장점인 JSON(JavaScript Object Notation)을 사용한다.

     ```json
     // GET /users/42 : id가 42인 사용자 데이터에 접근

     {
       "id": 42,
       "name": "yeslee",
       "address": {
         "city": "Yongin",
         "country": "South Korea"
       },
       "phoneNumber": 01012345678
     }
     ```

<hr>
<br>

## 데이터베이스

- 사용자가 늘어나면 서버 하나로는 충분하지 않기 때문에 여러 대의 서버를 두어야 한다.

  - 웹/모바일 트래픽 처리 서버: 웹 계층
  - 데이터베이스 서버: 데이터 계층

### 어떤 데이터베이스를 사용할 것인가?

- 관계형 데이터베이스, 관계형 데이터베이스 관리 시스템(RDBMS: Relational Data-base Management System)

  - MySQL, Oracle, PostgreSQL: table, row, column으로 자료를 표현한다.

  - SQL(Structured Query Language)을 사용하면 여러 테이블에 있는 데이터를 그 관계(relation)에 따라 합칠 수 있다(join).

- 비-관계형 데이터베이스(No SQL)

  - CouchDB, Neo4j, Cassandra, HBase, Amazon DynamoDB

  - 키-값 저장소(key-value store), 그래프 저장소(graph store), 칼럼 저장소(column store), 문서 저장소(document store) 4 부류로 나눠진다.

  - join 연산은 지원하지 않는다.

- RDB를 주로 사용하지만 다음과 같은 경우에는 No-SQL을 사용하는 것이 바람직하다.

  - 아주 낮은 응답 지연시간(latency)가 요구될 때

  - 비정형(unstructured) 데이터를 다룰 때: 동영상 파일, 오디오 파일, 사진, 문서, 메일 본문 등

  - 데이터(JSON, YAML, XML 등)를 직렬화(serialize) 혹은 역직렬화(deserialize)하기만 하면 될 때

  - 아주 많은 양의 데이터를 저장해야할 때

<hr>
<br>

## 수직적 규모 확장 vs 수평적 규모 확장

- 수직적 규모 확장(vertical scailing) 프로세스

  - 스케일 업(scale up), 서버에 고사양 자원을 추가한다.

  - 서버로 유입되는 트래픽의 양이 적을 때 사용하며 단순하다.

  - 한 대의 서버에 CPU나 메모리를 무한대로 증설하는데 한계가 있다.

  - 서버에 장애가 발생하면 웹사이트/앱은 완전히 중단되어 장애에 대한 자동복구(failover)나 다중화(redundancy) 방안을 제시하지 않는다.

- 수평적 규모 확장(horizonal scailing) 프로세스: 스케일 아웃(scale out), 더 많은 서버를 추가한다.

  - 대규모 애플리케이션을 지원하는데 적절하다.

  - 사용자는 웹 서버로 바로 연결되는데, 웹 서버가 다운되거나 너무 많은 사용자가 접속하여 웹 서버가 한계 상황에 도달하게 되면 응답 속도가 느려지거나 서버 접속이 불가능할 수 있다. -> 부하 분산기 또는 로드밸런서(load balancer)를 도입하는 이유

### 로드밸런서

- 부하 분산 집합(load balancing set)에 속한 웹 서버들에게 트래픽 부하를 고르게 분산한다.
  > 이미지
- 사용자가 로드밸런서의 공개 IP 주소(public IP address)로 접속할 때 웹 서버는 클라이언트의 접속을 직접 처리하지 않는다.

- 더 나은 보안을 위해, 서버간 통신에는 사설 IP 주소(private IP address)를 사용한다.

  > 사설 IP 주소
  >
  > - 같은 네트워크에 속한 서버 사이의 통신에만 쓰이는 IP 주소
  >
  > - 인터넷을 통해 접속할 수 없다.
  >
  > - 로드밸런서가 웹 서버와 통신할 때 사설 IP 주소를 이용한다.

- 부하 분산 집합에 또 하나의 웹 서버를 추가하면 장애를 자동복구하지 못하는 문제(failover)가 해소되고 웹 계층 가용성(availability)이 향상된다.

  - 서버 1이 다운되면(offline) 모든 트래픽은 서버 2로 전송되면서 웹 사이트 전체가 다운되는 일이 방지된다.

  - 부하를 나누기 위해 새로운 서버를 추가할 수도 있다.

  - 웹사이트로 유입되는 트래픽이 가파르게 증가하면 두 대의 서버로 트래픽을 감당할 수 없는 시점이 오는데, 웹 서버 계층에 더 많은 서버를 추가하면 로드밸런서가 자동적으로 트래픽을 분산한다.

### 데이터베이스 다중화

- 많은 데이터베이스 관리 시스템이 다중화를 지원한다.

- 보통은 서버 사이에 주(master) - 부(slave) 관계를 설정하고 데이터 원본은 주 서버에, 사본은 부 서버에 저장한다.

- 쓰기 연산(write operation)은 마스터에서만 지원한다.

- 부 데이터베이스는 주 데이터베이스부터 그 사본을 전달받으며, 읽기 연산(read operation)만을 지원한다.

- 데이터베이스를 변경하는 명령어들(insert, delete, update 등)은 주 데이터베이스로만 전달되어야한다.
- 대부분의 애플리케이션은 읽기 연산의 비중이 쓰기 연산보다 훨씬 높다.
- 따라서 부 데이터베이스의 수가 주 데이터베이스의 수보다 많다.
- 데이터베이스를 다중화할 때의 이점은 다음과 같다.

  - 더 나은 성능: 주-부 다중화 모델에서 모든 데이터 변경 연산은 주 데이터베이스 서버로만 전달되는데, 읽기 연산은 부 데이터베이스 서버들로 분산된다. 병렬로 처리될 수 있는 질의(query)의 수가 늘어나므로 성능이 좋아진다.
  - 안정성(reliability): 자연 재해 등의 이유로 데이터베이스 서버 가운데 일부가 파괴되어도 데이터는 보존된다. 데이터를 지역적으로 떨어진 여러 장소에 다중화시켜 놓을 수 있기 때문이다.
  - 가용성(availability): 데이터를 여러 지역에 복제해 둠으로써 하나의 데이터베이스 서버에 장애가 발생하더라도 다른 서버에 있는 데이터를 가져와 계속 서비스할 수 있게 된다.

- 데이터베이스 서버 가운데 하나가 다운된다면?

  - 부 서버가 한 대 뿐인데 다운된 경우
    - 읽기 연산은 한시적으로 모두 주 데이터베이스로 전달된다.
    - 즉시 새로운 부 데이터베이스 서버가 장애 서버를 대체한다.
  - 부 서버가 여러 대인 경우
    - 읽기 연산은 나머지 부 데이터베이스 서버로 분산된다.
    - 새로운 부 데이터베이스 서버가 장애 서버를 대체한다.

- 주 데이터베이스 서버가 다운된다면?

  - 한 대의 부 데이터베이스만 있는 경우
    - 해당 부 데이터베이스 서버가 새로운 주 서버가 된다.
    - 모든 데이터베이스 연산은 일시적으로 새로운 주 서버상에서 수행된다.
    - 새로운 부 서버가 추가될 것이다.
  - 프로덕션(production) 환경에서 벌어진다면 부 서버의 보관된 데이터가 최신 상태가 아닐 수 있기 때문에 더 복잡하다.
  - 없는 데이터는 복구 스크립트(recovery script)를 돌려서 추가해야 한다.
  - 다중 마스터(multi-master)나 원형 다중화(circular replication) 방식을 도입하면 이러한 상황에 대처하는데 도움이 될 수 있지만 해당 구성은 훨씬 복잡하며 여기서는 논의하지 않는다.

- 로드밸런서와 데이터베이스 다중화를 고려한 설계안
> 이미지

1. 사용자는 DNS로부터 로드밸런서의 공개 IP 주소를 받는다.
2. 사용자는 해당 IP 주소를 사용해 로드밸런서에 접속한다.
3. HTTP 요청은 서버 1이나 서버 2로 전달된다.
4. 웹 서버는 사용자의 데이터를 부 데이터베이스 서버에서 읽는다.
5. 웹 서버는 데이터 변경 연산(데이터 추가, 삭제, 갱신 등)은 주 데이터베이스로 전달한다.

- 응답시간(latency)은 캐시(cache)를 붙이고 정적 콘텐츠를 콘텐츠 전송 네트워크(Content Delivery Network, CDN)로 옮기면 개선할 수 있다.

## 캐시

- 값비싼 연산 결과 또는 자주 참조되는 데이터를 메모리 안에 두고, 뒤이은 요청이 보다 빨리 처리될 수 있도록 하는 저장소
- 애플리케이션 성능은 데이터베이스를 얼마나 자주 호출하느냐에 크게 좌우되는데, 캐시는 그런 문제를 완화한다.

### 캐시 계층(cache tier)

- 데이터가 잠시 보관되는 곳. 데이터베이스보다 훨씬 빠르다.
- 별도의 캐시 계층을 두면
  - 성능이 개선된다
  - 데이터베이스의 부하를 줄일 수 있다
  - 캐시 계층의 규모를 독립적으로 확장시키는 것도 가능하다

- 읽기 주도형 캐시 전략(read-though caching strategy)
  - 데이터에 캐시가 있으면 캐시에서 데이터를 읽어 웹 서버에 데이터를 반환한다.
  - 만약 데이터에 캐시가 없으면 데이터베이스에서 해당 데이터를 읽어 캐시에 저장한뒤 클라이언트에 반환한다.

- 대부분의 캐시 서버들이 일반적으로 널리 쓰이는 프로그래밍 언어로 API를 제공한다.
  ```python
  SECOND = 1
  cache.set('myKey', 'hello world!', 3600 + SECOND)
  cache.get('myKey')
  ```

### 캐시 사용 시 유의할 점

- 캐시는 어떤 상황에 바람직한가?
- 어떤 데이터를 캐시에 두어야 하는가?
  - 캐시는 데이터를 휘발성 메모리에 두기 때문에 중요한 데이터는 지속적 저장소(persistent data store)에 두어야 한다.
- 캐시에 보관된 데이터는 어떻게 만료(expire)되는가?
  - 이에 대한 정책을 마련해둠으로써 만료된 데이터는 캐시에서 삭제한다.
- 일관성(consistency)은 어떻게 유지되는가?
  - 일관성이란 데이터 저장소의 원본과 캐시 내의 사본이 같은지에 대한 여부다.
  - 저장소의 원본을 갱신하는 연산과 캐시를 갱신하는 연산은 단일 트랜잭션으로 처리되어야한다. (https://www.usenix.org/system/files/conference/nsdi13/nsdi13-final170_update.pdf 참고)
- 장애에는 어떻게 대처할 것인가?
  - 캐시 서버를 한 대만 두는 경우 해당 서버는 단일 장애 지점(Single Point of Failure, SPOF)이 될 가능성이 있다.
    > 단일 장애 지점: 어떤 특정 지점에서의 장애가 전체 시스템의 동작을 중단시켜버릴 수 있는 경우
  - 결과적으로 SPOF를 피하려면 여러 지역에 걸쳐 캐시 서버를 분산시켜야 한다.
- 캐시 메모리는 얼마나 크게 잡을 것인가?
  - 캐시 메모리가 너무 작으면 액세스 패턴에 따라서는 데이터가 너무 자주 캐시에서 밀려나버려(eviction) 캐시의 성능이 떨어진다.
  - 캐시 메모리를 과할당(overprovision)함으로서 캐시에 보관될 데이터가 갑자기 늘어났을 때 생기는 문제를 방지할 수 있다.
- 데이터 방출(eviction) 정책은 무엇인가?
  - 캐시 데이터 방출 정책: 캐시가 다 차버리면 추가로 캐시에 데이터를 넣어야하는 경우 기존 데이터를 내보내야 한다.
    - LRU(Least Recently Used): 마지막으로 사용된 시점이 가장 오래된 데이터를 내보내는 정책
    - LFU(Least Frequently Used): 사용된 빈도가 가장 낮은 데이터를 내보내는 정책
    - FIFO(First In First Out): 가장 먼저 캐시에 들어온 데이터를 가장 먼저 내보내는 정책

## 콘텐츠 전송 네트워크(CDN)

- 정적 콘텐츠를 전송하는 데 쓰이는, 지리적으로 분산된 서버의 네트워크
- 이미지, 비디오, CSS, JavaScript 파일 등을 캐시할 수 있다.
  > - 동적 콘텐츠 캐싱
  >
  > - 요청 경로(request path), 질의 문자열(query string), 쿠키(cookie), 요청 헤더(request header) 등의 정보에 기반하여 HTML 페이지를 캐시하는 것이다.

- 어떤 사용자가 웹사이트를 방문하면 그 사용자에게 가장 가까운 CDN 서버가 정적 콘텐츠를 전달한다
- 사용자가 CDN 서버로부터 멀면 멀수록 웹사이트는 천천히 로드될 것이다

- 어떻게 동작하는지?
  1. 사용자 A가 이미지 URL을 이용해 image.png에 접근한다. URL의 도메인은 CDN 서비스 사업자가 제공한 것이다.
  2. CDN 서버의 캐시에 해당 이미지가 없는 경우, 서버는 원본(origin) 서버에 요청하여 파일을 가져온다. 원본 서버는 웹 서버일 수도 있고 AWS S3같은 온라인 저장소일 수도 있다.
  3. 원본 서버가 파일을 CDN 서버에 반환한다. 응답이 HTTP 헤더에는 해당 파일이 얼마나 오래 캐시될 수 있는지를 설명하는 TTL(Time-To-Live) 값이 들어 있다.
  4. CDN 서버는 파일을 캐시하고 사용자 A에게 반환한다. 이미지는 TTL에 명시된 시간이 끝날 때까지 캐시된다.
  5. 사용자 B가 같은 이미지에 대한 요청을 CDN 서버에 전송한다.
  6. 만료되지 않은 이미지에 대한 요청은 캐시를 통해 처리된다.

### CDN 사용 시 고려해야 할 사항

- 비용
  - CDN은 보통 제3 사업자(third-party providers)에 의해 운영되며 CDN으로 들어가고 나가는 데이터 전송 양에 따라 비용을 지불한다.
  - 자주 사용되지 않는 콘텐츠는 CDN에서 빼는 것(캐싱하지 않는 것)이 낫다.
- 적절한 만료 시한 설정
  - 시의성이 중요한(time-sensitive) 콘텐츠의 경우 만료 시점을 잘 정해야 한다.
- CDN 장애에 대한 대처 방안
  - CDN 자체가 죽었을 경우 웹사이트/애플리케이션이 어떻게 동작해야 하는지 고려해야 한다.
- 콘텐츠 무효화(Invalidation)
  - 아직 만료되지 않은 콘텐츠라 하더라도 아래 방법 가운데 하나를 사용하면 CDN에서 제거할 수 있다.
    - CDN 서비스 사업자가 제공하는 API를 사용하여 콘텐츠 무효화
    - 콘텐츠의 다른 버전을 서비스하도록 오브젝트 버저닝(object versioning) 이용
    - 콘텐츠의 새로운 버전을 지정하기 위해서는 URL 마지막에 버전 번호를 인자로 주면 된다.(예. `image.png?v=2`)
  
- CDN과 캐시를 추가함으로서 정적 콘텐츠(JS, CSS, 이미지 등)등은 더 이상 웹 서버를 통해 서비스하지 않으며 CDN을 통해 제공해서 더 나은 성능을 보장한다.
- 캐시가 데이터베이스 부하를 줄여준다.

## 무상태(stateless) 웹 계층

- 웹 계층을 수평적으로 확장하기 위해 상태 정보(사용자 세션 데이터 같은)를 웹 계층에서 제거해야 한다.
- 무상태 웹 계층: 상태 정보를 관계형 데이터베이스나 NoSQL 같은 지속성 저장소에 보관하고, 필요할 때 가져오도록 한다.

### 상태 정보 의존적인 아키텍처

- 상태 정보를 보관하는 서버는 클라이언트 정보, 즉 상태를 유지하여 요청들 사이에 공유되도록 하는데 무상태 서버에는 이런 장치가 없다.
- 사용자 A의 세션 정보나 프로파일 이미지 같은 상태 정보는 서버 1에 저장되는데 사용자 A를 인증하기 위해 HTTP 요청은 반드시 서버 1로 전송되어야 한다.
  - 요청이 서버 2로 전송되면, 서버 2에는 사용자 A에 관한 데이터는 보관되어있지 않기 때문에 인증은 실패한다.
- 즉, 같은 클라이언트로부터의 요청은 항상 같은 서버로 전송되어야 한다.
- 대부분의 로드밸런서가 이를 지원하기 위해 고정 세션(sticky session)이라는 기능을 제공하는데 이는 로드밸런서에게 부담을 준다.
- 또한 로드밸런서 뒷단에 서버를 추가하거나 제거하기도 까다로워지므로 이들 서버의 장애를 처리하기도 복잡해진다.

### 무상태 아키텍처

- 사용자로부터 HTTP 요청은 